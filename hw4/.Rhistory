train = Weekly[!test_rows,]
nrow(train)
nrow(test)
!test_rows
test_rows = [1:121]
train = Weekly[fold[!test_rows],]
nrow(train)
!test_rows
fold[!test_rows]
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=4, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test
ERR1
122*2
test  = Weekly[fold[122:244],]
train1 = Weekly[fold[(245:1089)],]
train2 = Weekly[fold[1:121],]
train = cbind(train1,train2)
test  = Weekly[fold[122:244],]
train1 = Weekly[fold[(245:1089)],]
train2 = Weekly[fold[1:121],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=4, lag.data = data.frame(cbind(test[2:6])))
}
ERR2= sum(predictions != test$Direction)/n.test
ERR2
121*3
363-245+1
121*2
363-242+1
363-243+1
test  = Weekly[fold[243:363],]
train1 = Weekly[fold[(364:1089)],]
train2 = Weekly[fold[1:242],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=4, lag.data = data.frame(cbind(test[2:6])))
}
ERR3= sum(predictions != test$Direction)/n.test;ERR3
ERR[3,]= ERR3
EER
ERR
ERR[1,]
ERR[,1]
ERR[,3]= ERR3
ERR3= sum(predictions != test$Direction)/n.test;ERR3
121*4
test  = Weekly[fold[244:484],]
train1 = Weekly[fold[(485:1089)],]
train2 = Weekly[fold[1:243],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=4, lag.data = data.frame(cbind(test[2:6])))
}
ERR4= sum(predictions != test$Direction)/n.test;ERR4
ERR[,4]= ERR4
for (i in 2:9){
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089)],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
mean(ERR)
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#K=1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
mean(ERR)
cv = matrix NA, nrow = 1, ncol = 3, dimnames=list(NULL,c("K=1","K=3","K=7"))
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
cv = matrix (NA, nrow = 1, ncol = 3, dimnames=list(NULL,c("K=1","K=3","K=7"))
/
,;,
cv = matrix (NA, nrow = 1, ncol = 3, dimnames=list(NULL,c("K=1","K=3","K=7"))
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
cv = matrix (NA, nrow = 1, ncol = 3, dimnames=list(NULL,c("K=1","K=3","K=7")))
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=1, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=1, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV[1] = mean(ERR);CV[1]
cv[,1] = CV[1]
CV1 = mean(ERR);CV1
cv[,1] = CV1
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=3, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=3, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV3 = mean(ERR);CV3
cv[,2] = CV3
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=7, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=7, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV7 = mean(ERR);CV7
cv[,3] = CV7
cv
cv = matrix (NA, nrow = 1, ncol = 3, dimnames=list(NULL,c("K=1","K=3","K=7")))
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
##For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=1, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
## k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=1, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV1 = mean(ERR);CV1
cv[,1] = CV1
#K=3
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#For k = 1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=3, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=3, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV3 = mean(ERR);CV3
cv[,2] = CV3
For K = 7
KNN.decision(new.point, K=5, lag.data)
lag.data = data.frame(cbind(Weekly[2:6]))
KNN.decision <- function(new.point = c(1:5), K = 5, lag.data) {
n <- nrow(lag.data)
stopifnot(K <= n)
stopifnot( length(new.point) == 5, ncol(lag.data) == 5, K <= n)
dists = sqrt((lag.data[,1]-new.point[1])^2 + (lag.data[,2]-new.point[2])^2+(lag.data[,3]-new.point[3])^2+(lag.data[,4]-new.point[4])^2+(lag.data[,5]-new.point[5])^2)
ord.indices <- sort(dists, index.return = TRUE)[[2]]
neighb.dir  <- Weekly$Direction[ord.indices[1:K]]
choice      <- names(which.max(table(neighb.dir)))
return(choice)
}
# If I use a vector: new.point = c(2.1,2.3,2.4,2.7,2.8), which has length 5 to test the KNN function:
new.point = c(2.1,2.3,2.4,2.7,2.8)
KNN.decision(new.point, K=5, lag.data)
length(new.point)
ncol(lag.data)
new.point = c(2.1,2.3,2.4,2.7,2.8)
length(new.point)
ncol(lag.data)
KNN.decision(new.point, K=5, lag.data)
test  = Weekly[Weekly$Year <= 2008, ]
train <- Weekly[Weekly$Year > 2008,]
n.test <- nrow(test)
predictions <- rep(NA, n.test)
for (i in 1:n.test){
predictions[i] <- KNN.decision(new.point=c(test$Lag1[i],test$Lag2[i],test$Lag3[i],test$Lag4[i],test$Lag5[i]),K=5, lag.data = data.frame(cbind(test[2:6])))
}
test.error <- sum(predictions != test$Direction)/n.test
test.error
test  = Weekly[Weekly$Year <= 2008, ]
train <- Weekly[Weekly$Year > 2008,]
n.test <- nrow(test)
predictions <- rep(NA, n.test)
for (i in 1:n.test){
predictions[i] <- KNN.decision(new.point=c(test$Lag1[i],test$Lag2[i],test$Lag3[i],test$Lag4[i],test$Lag5[i]), K=3, lag.data = data.frame(cbind(test[2:6])))
}
test.error <- sum(predictions != test$Direction)/n.test
test.error
ERR = matrix(NA, nrow = 1, ncol = 9, dimnames=list(NULL,c("ERR1","ERR2","ERR3","ERR4","ERR5","ERR6","ERR7","ERR8","ERR9")))
#K=1
test  = Weekly[fold[1:121],]
train = Weekly[fold[(122:1089)]]
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR1= sum(predictions != test$Direction)/n.test ;ERR1
ERR[,1] = ERR1
# k = 2 TO k = 9
for (i in 2:9)
{
test  = Weekly[fold[((i-1)*121+1):(i*121)],]
train1 = Weekly[fold[(i*121+1):1089],]
train2 = Weekly[fold[1:(121*(i-1))],]
train = rbind(train1,train2)
n.test = nrow(test)
predictions <- rep(NA, n.test)
for (b in 1:n.test){
predictions[b] <- KNN.decision(new.point=c(test$Lag1[b],test$Lag2[b],test$Lag3[b],test$Lag4[b],test$Lag5[b]), K=5, lag.data = data.frame(cbind(test[2:6])))
}
ERR[i]= sum(predictions != test$Direction)/n.test;ERR[i]
ERR[,i]=ERR[i]
}
ERR
CV = mean(ERR);CV
hw3 = "~/Desktop/2016 fall/regression/data/copier_maintenance.txt"
copier = read.table(file = hw3, head = T)
names(copier)
dotchart(copier$copiers, xlab = "copier", main = "Cleveland dot plot of Copiers")
lm0 = lm(copier$minutes~ copier$copiers)
resid = lm0$residuals
boxplot(resid)
plot(copier$minutes~resid, ylab = "minutes",xlab = "residuals", main = "minutes v.s residuals")
plot(lm0$fitted~resid,ylab = "copiers",xlab = "residuals", main = "copiers v.s residuals")
qqnorm(resid)
ts.plot(resid)
library("FitAR", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("FitARMA", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
acf(resid)
full = "~/Desktop/2016 fall/regression/data/copiers_full.txt"
copier_full = read.table(file = full, head = T)
plot(copier_full$age~resid,ylab = "age",xlab = "residuals", main = "age v.s residuals")
plot(copier_full$experience~resid,ylab = "experience",xlab = "residuals", main = "experience v.s residuals")
```
lm1 = lm(crime$y~crime$x)
crime = "~/Desktop/2016 fall/regression/data/crime_rates.txt"
crime = read.table(file = crime, head = T)
y1 = crime$y[crime$x==84]
hist(y1, prob = T, main ="HS graduation rate for n = 84",xlab = "high school graduation rates")
lines(density(y1,adjust = 2))
lm1 = lm(crime$y~crime$x)
residuals = lm1$residuals
hist(lm1$residuals,main = "histogram of residuals",xlab = "residuals")
y_hat = lm1$fitted
plot(y_hat~residuals,main = "Y-hay v.s residuals")
qqnorm(residuals)
qqnorm(resid)
qqnorm(residuals)
senic = "~/Desktop/2016 fall/regression/data/SENIC.txt"
senic = read.table(file = senic, head = T)
names(senic)
stay = senic$Stay
afs = senic$AFS
age = senic$Age
xray = senic$Xray
lm01 = lm(stay~afs)
lm02 = lm(stay~age)
lm03 = lm(stay~xray)
plot(lm01$fitted~lm01$residuals,main = "Stay~AFS: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
plot(lm02$fitted~lm02$residuals,main = "Stay~Age: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
plot(lm03$fitted~lm03$residuals,main = "Stay~Xrays: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
senic = "~/Desktop/2016 fall/regression/data/SENIC.txt"
senic = read.table(file = senic, head = T)
names(senic)
stay = senic$Stay
afs = senic$AFS
age = senic$Age
xray = senic$Xray
lm01 = lm(stay~afs)
lm02 = lm(stay~age)
lm03 = lm(stay~xray)
plot(lm01$fitted~lm01$residuals,main = "Stay~AFS: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
plot(lm02$fitted~lm02$residuals,main = "Stay~Age: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
plot(lm03$fitted~lm03$residuals,main = "Stay~Xrays: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
# In the above plots, all the residuals plots have two noticeble outliers. Besides, all the plots have non-linear pattern, thus all the vriance in the 3 models are constant.
risk=senic$Risk
lm04 = lm(stay~risk)
plot(lm04$fitted~lm04$residuals,main = "Stay~Risk: fitted v.s residuals",ylab = "fitted value",xlab = "residuals")
identify(lm04$fitted,lm04$residuals , plot=TRUE)
identify(lm04$fitted,lm04$residuals , plot=TRUE)
new.senic = data.frame(senic[c(-47,-112)])
lm05 = lm (new.senic$Stay~new.senic$Risk)
plot(lm05$residuals~lm05$fitted)
plot(lm05$residuals~lm05$fitted, main = "Stay~Risk: fitted v.s residuals ",xlab = "residuals", ylab = "fitted value")
x = c(senic$Risk[47],senic$Risk[112])
PI = predict(fit.new,data.frame(Risk = x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(Risk = x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(senic$Risk = x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame( x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(risk = x), interval ="prediction", level = 0.95)
PI
PI = predict(lm05,data.frame(risk), interval ="prediction", level = 0.95)
PI
senic$Stay[c(47,112)]
?predict
PI = predict(lm05,data.frame(x), interval ="prediction", level = 0.95)
PI = predict(lm05,x, interval ="prediction", level = 0.95)
x = c(senic$Risk[47],senic$Risk[112])
PI = predict(lm05, x, interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(x), interval ="prediction", level = 0.95)
PI = predict(lm05,newdata = x , interval ="prediction", level = 0.95)
x = data.frame(c(senic$Risk[47],senic$Risk[112]))
x
x = data.frame(c(senic$Risk[47],senic$Risk[112]),head = FALSE)
X
x
x = data.frame(c(senic$Risk[47],senic$Risk[112]))
PI = predict(lm05,newdata = x , interval ="prediction", level = 0.95)
lm05 = lm (new.senic$Stay~new.senic$Risk)
PI = predict(lm05,newdata = x , interval ="prediction", level = 0.95)
new.senic = data.frame(senic[c(-47,-112)])
stay1= new.senic$Stay
risk1 = new.senic$Risk
lm05 = lm (stay1~risk1)
plot(lm05$residuals~lm05$fitted, main = "Stay~Risk: fitted v.s residuals ",xlab = "residuals", ylab = "fitted value")
x = data.frame(c(senic$Risk[47],senic$Risk[112]))
PI = predict(lm05,newdata = x , interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(risk1=x), interval ="prediction", level = 0.95)
PI = predict(lm05,data.frame(risk=x), interval ="prediction", level = 0.95)
PI
senic$Stay[c(47,112)]
hw3 = "~/Desktop/2016 fall/regression/data/copier_maintenance.txt"
copier = read.table(file = hw3, head = T)
names(copier)
dotchart(copier$copiers, xlab = "copier", main = "Cleveland dot plot of Copiers")
crime = "~/Desktop/2016 fall/regression/data/crime_rates.txt"
crime = read.table(file = crime, head = T)
y1 = crime$x
hist(y1, prob = T, main ="HS graduation rate for n = 84",xlab = "high school graduation rates")
lines(density(y1,adjust = 2))
# The density line is not symmetric, and it is clearly skwed to the right.
setwd("~/Desktop/2016 fall/5206/hw4")
hw4 = "~/Desktop/2016 fall/5206/hw4/gmp.txt"
gmp <- read.table("gmp.txt", header = TRUE)
gmp$pop <- round(gmp$gmp/gmp$pcgmp)
names(gmp)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
ggplot(data = mpg) + geom_point(mapping = aes(x = pop, y = gmp))
ggplot(data = gmp) + geom_point(mapping = aes(x = gmp$pop, y = gmp$gmp))
ggplot(data = gmp) + geom_point(mapping = aes(x = gmp$pop, y = gmp))
ggplot(data = gmp) + geom_point(mapping = aes(x = pop, y = gmp))
> plot(gmp$pop, gmp$pcgmp, log = "x", xlab = "Population",
+      ylab = "Per-capita Economic Output")
plot(gmp$pop, gmp$pcgmp, log = "x", xlab = "Population",ylab = "Per-capita Economic Output")
beta_0 = 6611
beta_1 = 1/8
curve(6611*x^{1/8}, add = TRUE, col = "blue")
curve(6611*x^{0.1}.add = TRUE,col = "blue")
curve(6611*x^{0.1},add = TRUE,col = "red")
curve(6611*x^{0.5},add = TRUE,col = "green")
curve(6611*x^{0.5},add = TRUE,col = "red")
curve(6611*x^{0.15},add = TRUE,col = "green")
v = c(6611,0.15)
v = c(6611,0.15)
x = gmp$pop
y = gmp$gmp
mse = funciton (v,x,y){
mse = sum((y - v[1]*x^v[2])^2)/length(x)
mse = funciton (v,x,y)
mse = funciton(v,x,y)
mse = funciton(v,x,y){
v = c(6611,0.15)
x = gmp$pop
y = gmp$gmp
mse = funciton(v,x,y){
mse = funciton(v,x,y){
